// Code generated by delegatorgen. DO NOT EDIT.

package delegatorgen

import (
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/codes"
	"go.opentelemetry.io/otel/trace"
	"math/rand"
	"sync"
	"time"
)

// =============================================================================
// Delegator Interfaces
// =============================================================================

// UserRepositoryCachedResult represents a cached value with metadata.
// Users must implement this interface to integrate with their cache library.
type UserRepositoryCachedResult interface {
	// Value returns the cached data.
	// If IsError() returns true, this returns the cached error.
	Value() any
	// ExpiresAt returns the expiration time (used for async refresh decision).
	ExpiresAt() time.Time
	// IsError returns true if this is an error cache entry (for cache penetration prevention).
	IsError() bool
}

// UserRepositoryCache is a generic caching interface.
// Implement this interface to integrate with your cache library (e.g., Redis, in-memory).
type UserRepositoryCache interface {
	// Get retrieves cached result by key.
	// Returns the cached result and whether the key was found.
	Get(ctx context.Context, key string) (result UserRepositoryCachedResult, ok bool)

	// Set stores a value with the given TTL.
	Set(ctx context.Context, key string, value any, ttl time.Duration) error

	// SetError decides whether to cache an error and stores it if needed.
	// Returns shouldCache=true if the error was cached.
	SetError(ctx context.Context, key string, err error, ttl time.Duration) (shouldCache bool, cacheErr error)

	// Delete removes one or more keys from the cache.
	Delete(ctx context.Context, keys ...string) error
}

// UserRepositoryCacheLocker is an optional interface for distributed locking.
// If your cache implementation also implements this interface,
// the cache delegator will automatically use it to prevent cache stampede.
type UserRepositoryCacheLocker interface {
	// Lock acquires a distributed lock for the given key.
	// Returns a release function and whether the lock was acquired.
	Lock(ctx context.Context, key string) (release func(), acquired bool)
}

// UserRepositoryCacheAsyncExecutor is an optional interface for async cache refresh.
// If your cache implementation also implements this interface,
// the cache delegator will automatically use it to refresh cache entries in the background.
type UserRepositoryCacheAsyncExecutor interface {
	// Submit submits a task for async execution.
	Submit(task func())
}

// =============================================================================
// Builder
// =============================================================================

// UserRepositoryDelegatorFunc is a function that wraps a UserRepository.
type UserRepositoryDelegatorFunc func(UserRepository) UserRepository

// UserRepositoryDelegator builds a UserRepository with delegators.
type UserRepositoryDelegator struct {
	base       UserRepository
	delegators []UserRepositoryDelegatorFunc
}

// NewUserRepositoryDelegator creates a new delegator builder.
func NewUserRepositoryDelegator(base UserRepository) *UserRepositoryDelegator {
	return &UserRepositoryDelegator{base: base}
}

// Use adds a custom delegator.
// Delegators are applied in order: first added = outermost (executes first).
func (d *UserRepositoryDelegator) Use(mw UserRepositoryDelegatorFunc) *UserRepositoryDelegator {
	d.delegators = append(d.delegators, mw)
	return d
}

// WithCache adds caching delegator.
// Advanced features (distributed lock, async refresh) are automatically enabled
// if the cache implementation also implements CacheLocker or CacheAsyncExecutor.
func (d *UserRepositoryDelegator) WithCache(cache UserRepositoryCache) *UserRepositoryDelegator {
	return d.Use(func(next UserRepository) UserRepository {
		return newUserRepositoryCacheDelegator(next, cache)
	})
}

// WithTracing adds tracing delegator using OpenTelemetry.
func (d *UserRepositoryDelegator) WithTracing(tracer trace.Tracer) *UserRepositoryDelegator {
	return d.Use(func(next UserRepository) UserRepository {
		return &userRepositoryTracingDelegator{next: next, tracer: tracer}
	})
}

// Build creates the final UserRepository with all delegators applied.
// Delegators are applied in reverse order so that the first added delegator
// is the outermost (executes first).
func (d *UserRepositoryDelegator) Build() UserRepository {
	result := d.base
	for i := len(d.delegators) - 1; i >= 0; i-- {
		result = d.delegators[i](result)
	}
	return result
}

// =============================================================================
// Cache Delegator
// =============================================================================

type userRepositoryCacheDelegator struct {
	next          UserRepository
	cache         UserRepositoryCache
	locker        UserRepositoryCacheLocker
	asyncExecutor UserRepositoryCacheAsyncExecutor
	refreshing    sync.Map
}

func newUserRepositoryCacheDelegator(next UserRepository, cache UserRepositoryCache) *userRepositoryCacheDelegator {
	m := &userRepositoryCacheDelegator{
		next:  next,
		cache: cache,
	}

	// Runtime detection of optional capabilities
	if locker, ok := cache.(UserRepositoryCacheLocker); ok {
		m.locker = locker
	}
	if executor, ok := cache.(UserRepositoryCacheAsyncExecutor); ok {
		m.asyncExecutor = executor
	}

	return m
}

func (d *userRepositoryCacheDelegator) GetByID(ctx context.Context, id string) (*User, error) {
	// Compile-time constants from annotation
	const (
		baseTTL        = 5 * time.Minute
		jitterPercent  = 10
		refreshPercent = 20
	)

	// Build cache key
	keySuffix, err := func() (string, error) {
		s, err := base64JSONEncode(id)
		if err != nil {
			return "", err
		}
		return "GetByID:" + s, nil
	}()
	if err != nil {
		return nil, err
	}
	key := "github.com/tlipoca9/devgen/examples/delegatorgen:UserRepository:" + keySuffix

	// Check cache
	if res, ok := d.cache.Get(ctx, key); ok {
		// Check if error cache
		if res.IsError() {
			if err, ok := res.Value().(error); ok {
				return nil, err
			}
			goto cacheMiss
		}

		// Type assertion
		value, ok := res.Value().(*User)
		if !ok {
			goto cacheMiss
		}

		// Async refresh check
		if d.asyncExecutor != nil && refreshPercent > 0 {
			remaining := time.Until(res.ExpiresAt())
			threshold := baseTTL * time.Duration(refreshPercent) / 100
			if remaining > 0 && remaining < threshold {
				if _, loaded := d.refreshing.LoadOrStore(key, struct{}{}); !loaded {
					d.asyncExecutor.Submit(func() {
						defer d.refreshing.Delete(key)
						d.refreshGetByIDCache(context.Background(), key, id)
					})
				}
			}
		}

		return value, nil
	}

cacheMiss:
	// Distributed lock (if available)
	if d.locker != nil {
		release, acquired := d.locker.Lock(ctx, key)
		if acquired {
			defer release()
			// Double-check after acquiring lock
			if res, ok := d.cache.Get(ctx, key); ok {
				if res.IsError() {
					if err, ok := res.Value().(error); ok {
						return nil, err
					}
				} else if value, ok := res.Value().(*User); ok {
					return value, nil
				}
			}
		}
	}

	// Call downstream
	result, err := d.next.GetByID(ctx, id)

	// Calculate TTL with jitter
	ttl := userRepositoryCalculateTTL(baseTTL, jitterPercent)

	if err != nil {
		// Let cache implementation decide whether to cache this error
		d.cache.SetError(ctx, key, err, ttl)
		return nil, err
	}

	// Store in cache
	d.cache.Set(ctx, key, result, ttl)
	return result, nil
}

func (d *userRepositoryCacheDelegator) refreshGetByIDCache(ctx context.Context, key string, id string) {
	const (
		baseTTL        = 5 * time.Minute
		jitterPercent  = 10
		refreshPercent = 20
	)

	// Lock to prevent concurrent refresh
	if d.locker != nil {
		release, acquired := d.locker.Lock(ctx, key)
		if !acquired {
			return
		}
		defer release()

		// Double-check if still needs refresh
		if res, ok := d.cache.Get(ctx, key); ok {
			remaining := time.Until(res.ExpiresAt())
			threshold := baseTTL * time.Duration(refreshPercent) / 100
			if remaining >= threshold {
				return
			}
		}
	}

	result, err := d.next.GetByID(ctx, id)
	if err != nil {
		return // Keep old cache on refresh failure
	}

	ttl := userRepositoryCalculateTTL(baseTTL, jitterPercent)
	d.cache.Set(ctx, key, result, ttl)
}

func (d *userRepositoryCacheDelegator) GetByEmail(ctx context.Context, email string) (*User, error) {
	// Compile-time constants from annotation
	const (
		baseTTL        = 10 * time.Minute
		jitterPercent  = 10
		refreshPercent = 20
	)

	// Build cache key
	key := "github.com/tlipoca9/devgen/examples/delegatorgen:UserRepository:" + fmt.Sprintf("user:email:%v", email)

	// Check cache
	if res, ok := d.cache.Get(ctx, key); ok {
		// Check if error cache
		if res.IsError() {
			if err, ok := res.Value().(error); ok {
				return nil, err
			}
			goto cacheMiss
		}

		// Type assertion
		value, ok := res.Value().(*User)
		if !ok {
			goto cacheMiss
		}

		// Async refresh check
		if d.asyncExecutor != nil && refreshPercent > 0 {
			remaining := time.Until(res.ExpiresAt())
			threshold := baseTTL * time.Duration(refreshPercent) / 100
			if remaining > 0 && remaining < threshold {
				if _, loaded := d.refreshing.LoadOrStore(key, struct{}{}); !loaded {
					d.asyncExecutor.Submit(func() {
						defer d.refreshing.Delete(key)
						d.refreshGetByEmailCache(context.Background(), key, email)
					})
				}
			}
		}

		return value, nil
	}

cacheMiss:
	// Distributed lock (if available)
	if d.locker != nil {
		release, acquired := d.locker.Lock(ctx, key)
		if acquired {
			defer release()
			// Double-check after acquiring lock
			if res, ok := d.cache.Get(ctx, key); ok {
				if res.IsError() {
					if err, ok := res.Value().(error); ok {
						return nil, err
					}
				} else if value, ok := res.Value().(*User); ok {
					return value, nil
				}
			}
		}
	}

	// Call downstream
	result, err := d.next.GetByEmail(ctx, email)

	// Calculate TTL with jitter
	ttl := userRepositoryCalculateTTL(baseTTL, jitterPercent)

	if err != nil {
		// Let cache implementation decide whether to cache this error
		d.cache.SetError(ctx, key, err, ttl)
		return nil, err
	}

	// Store in cache
	d.cache.Set(ctx, key, result, ttl)
	return result, nil
}

func (d *userRepositoryCacheDelegator) refreshGetByEmailCache(ctx context.Context, key string, email string) {
	const (
		baseTTL        = 10 * time.Minute
		jitterPercent  = 10
		refreshPercent = 20
	)

	// Lock to prevent concurrent refresh
	if d.locker != nil {
		release, acquired := d.locker.Lock(ctx, key)
		if !acquired {
			return
		}
		defer release()

		// Double-check if still needs refresh
		if res, ok := d.cache.Get(ctx, key); ok {
			remaining := time.Until(res.ExpiresAt())
			threshold := baseTTL * time.Duration(refreshPercent) / 100
			if remaining >= threshold {
				return
			}
		}
	}

	result, err := d.next.GetByEmail(ctx, email)
	if err != nil {
		return // Keep old cache on refresh failure
	}

	ttl := userRepositoryCalculateTTL(baseTTL, jitterPercent)
	d.cache.Set(ctx, key, result, ttl)
}

func (d *userRepositoryCacheDelegator) List(ctx context.Context, offset int, limit int) ([]*User, error) {
	// Compile-time constants from annotation
	const (
		baseTTL        = 2 * time.Minute
		jitterPercent  = 10
		refreshPercent = 20
	)

	// Build cache key
	keySuffix, err := func() (string, error) {
		s, err := base64JSONEncode(offset, limit)
		if err != nil {
			return "", err
		}
		return "List:" + s, nil
	}()
	if err != nil {
		return nil, err
	}
	key := "users:list" + keySuffix

	// Check cache
	if res, ok := d.cache.Get(ctx, key); ok {
		// Check if error cache
		if res.IsError() {
			if err, ok := res.Value().(error); ok {
				return nil, err
			}
			goto cacheMiss
		}

		// Type assertion
		value, ok := res.Value().([]*User)
		if !ok {
			goto cacheMiss
		}

		// Async refresh check
		if d.asyncExecutor != nil && refreshPercent > 0 {
			remaining := time.Until(res.ExpiresAt())
			threshold := baseTTL * time.Duration(refreshPercent) / 100
			if remaining > 0 && remaining < threshold {
				if _, loaded := d.refreshing.LoadOrStore(key, struct{}{}); !loaded {
					d.asyncExecutor.Submit(func() {
						defer d.refreshing.Delete(key)
						d.refreshListCache(context.Background(), key, offset, limit)
					})
				}
			}
		}

		return value, nil
	}

cacheMiss:
	// Distributed lock (if available)
	if d.locker != nil {
		release, acquired := d.locker.Lock(ctx, key)
		if acquired {
			defer release()
			// Double-check after acquiring lock
			if res, ok := d.cache.Get(ctx, key); ok {
				if res.IsError() {
					if err, ok := res.Value().(error); ok {
						return nil, err
					}
				} else if value, ok := res.Value().([]*User); ok {
					return value, nil
				}
			}
		}
	}

	// Call downstream
	result, err := d.next.List(ctx, offset, limit)

	// Calculate TTL with jitter
	ttl := userRepositoryCalculateTTL(baseTTL, jitterPercent)

	if err != nil {
		// Let cache implementation decide whether to cache this error
		d.cache.SetError(ctx, key, err, ttl)
		return nil, err
	}

	// Store in cache
	d.cache.Set(ctx, key, result, ttl)
	return result, nil
}

func (d *userRepositoryCacheDelegator) refreshListCache(ctx context.Context, key string, offset int, limit int) {
	const (
		baseTTL        = 2 * time.Minute
		jitterPercent  = 10
		refreshPercent = 20
	)

	// Lock to prevent concurrent refresh
	if d.locker != nil {
		release, acquired := d.locker.Lock(ctx, key)
		if !acquired {
			return
		}
		defer release()

		// Double-check if still needs refresh
		if res, ok := d.cache.Get(ctx, key); ok {
			remaining := time.Until(res.ExpiresAt())
			threshold := baseTTL * time.Duration(refreshPercent) / 100
			if remaining >= threshold {
				return
			}
		}
	}

	result, err := d.next.List(ctx, offset, limit)
	if err != nil {
		return // Keep old cache on refresh failure
	}

	ttl := userRepositoryCalculateTTL(baseTTL, jitterPercent)
	d.cache.Set(ctx, key, result, ttl)
}

func (d *userRepositoryCacheDelegator) Save(ctx context.Context, user *User) error {
	err := d.next.Save(ctx, user)
	if err == nil {
		d.cache.Delete(ctx, fmt.Sprintf("user:id:%v", user.ID))
	}
	return err
}

func (d *userRepositoryCacheDelegator) Delete(ctx context.Context, id string) error {
	err := d.next.Delete(ctx, id)
	if err == nil {
		d.cache.Delete(ctx, fmt.Sprintf("user:id:%v", id))
	}
	return err
}

// =============================================================================
// Tracing Delegator
// =============================================================================

type userRepositoryTracingDelegator struct {
	next   UserRepository
	tracer trace.Tracer
}

func (d *userRepositoryTracingDelegator) GetByID(ctx context.Context, id string) (*User, error) {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.UserRepository.GetByID`,
		trace.WithAttributes(
			attribute.String("id", id),
		))
	defer span.End()

	result, err := d.next.GetByID(ctx, id)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return result, err
}

func (d *userRepositoryTracingDelegator) GetByEmail(ctx context.Context, email string) (*User, error) {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.UserRepository.GetByEmail`)
	defer span.End()

	result, err := d.next.GetByEmail(ctx, email)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return result, err
}

func (d *userRepositoryTracingDelegator) List(ctx context.Context, offset int, limit int) ([]*User, error) {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.UserRepository.List`,
		trace.WithAttributes(
			attribute.Int64("offset", int64(offset)),
		))
	defer span.End()

	result, err := d.next.List(ctx, offset, limit)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return result, err
}

func (d *userRepositoryTracingDelegator) Save(ctx context.Context, user *User) error {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.UserRepository.Save`)
	defer span.End()

	err := d.next.Save(ctx, user)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return err
}

func (d *userRepositoryTracingDelegator) Delete(ctx context.Context, id string) error {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.UserRepository.Delete`,
		trace.WithAttributes(
			attribute.String("id", id),
		))
	defer span.End()

	err := d.next.Delete(ctx, id)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return err
}

// =============================================================================
// Helper Functions
// =============================================================================

// base64JSONEncode encodes arguments as JSON then Base64.
func base64JSONEncode(args ...any) (string, error) {
	var data []byte
	var err error
	if len(args) == 1 {
		data, err = json.Marshal(args[0])
	} else {
		data, err = json.Marshal(args)
	}
	if err != nil {
		return "", err
	}
	return base64.StdEncoding.EncodeToString(data), nil
}

// userRepositoryCalculateTTL calculates TTL with jitter.
func userRepositoryCalculateTTL(baseTTL time.Duration, jitterPercent int) time.Duration {
	if jitterPercent <= 0 {
		return baseTTL
	}
	jitter := float64(jitterPercent) / 100.0
	factor := 1.0 + (rand.Float64()*2-1)*jitter
	return time.Duration(float64(baseTTL) * factor)
}

// =============================================================================
// Delegator Interfaces
// =============================================================================

// =============================================================================
// Builder
// =============================================================================

// OrderRepositoryDelegatorFunc is a function that wraps a OrderRepository.
type OrderRepositoryDelegatorFunc func(OrderRepository) OrderRepository

// OrderRepositoryDelegator builds a OrderRepository with delegators.
type OrderRepositoryDelegator struct {
	base       OrderRepository
	delegators []OrderRepositoryDelegatorFunc
}

// NewOrderRepositoryDelegator creates a new delegator builder.
func NewOrderRepositoryDelegator(base OrderRepository) *OrderRepositoryDelegator {
	return &OrderRepositoryDelegator{base: base}
}

// Use adds a custom delegator.
// Delegators are applied in order: first added = outermost (executes first).
func (d *OrderRepositoryDelegator) Use(mw OrderRepositoryDelegatorFunc) *OrderRepositoryDelegator {
	d.delegators = append(d.delegators, mw)
	return d
}

// WithTracing adds tracing delegator using OpenTelemetry.
func (d *OrderRepositoryDelegator) WithTracing(tracer trace.Tracer) *OrderRepositoryDelegator {
	return d.Use(func(next OrderRepository) OrderRepository {
		return &orderRepositoryTracingDelegator{next: next, tracer: tracer}
	})
}

// Build creates the final OrderRepository with all delegators applied.
// Delegators are applied in reverse order so that the first added delegator
// is the outermost (executes first).
func (d *OrderRepositoryDelegator) Build() OrderRepository {
	result := d.base
	for i := len(d.delegators) - 1; i >= 0; i-- {
		result = d.delegators[i](result)
	}
	return result
}

// =============================================================================
// Tracing Delegator
// =============================================================================

type orderRepositoryTracingDelegator struct {
	next   OrderRepository
	tracer trace.Tracer
}

func (d *orderRepositoryTracingDelegator) GetByID(ctx context.Context, id string) (*Order, error) {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.OrderRepository.GetByID`,
		trace.WithAttributes(
			attribute.String("id", id),
		))
	defer span.End()

	result, err := d.next.GetByID(ctx, id)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return result, err
}

func (d *orderRepositoryTracingDelegator) Create(ctx context.Context, order *Order) error {
	ctx, span := d.tracer.Start(ctx, `github.com/tlipoca9/devgen/examples/delegatorgen.OrderRepository.Create`)
	defer span.End()

	err := d.next.Create(ctx, order)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, err.Error())
	}
	return err
}

// =============================================================================
// Helper Functions
// =============================================================================
